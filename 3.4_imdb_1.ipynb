{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMDB 电影评论分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from keras import losses\n",
    "from keras import metrics\n",
    "from keras.datasets import imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_WORD_NUMS = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_datas, train_labels), (test_datas, test_labels) = imdb.load_data(num_words=MAX_WORD_NUMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000,)\n",
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n",
      "(25000,)\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(train_datas.shape)\n",
    "print(train_datas[0])\n",
    "print(train_labels.shape)\n",
    "print(train_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9999"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 求最大单词索引\n",
    "max([max(word_indexs) for word_indexs in train_datas])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 向量化评论\n",
    "def vectorization_comments(comments):\n",
    "    x = np.zeros((comments.shape[0], MAX_WORD_NUMS))\n",
    "    for i, comment in enumerate(comments):\n",
    "        x[i, comment] = 1\n",
    "        \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = vectorization_comments(train_datas)\n",
    "x_test = vectorization_comments(test_datas)\n",
    "\n",
    "y_train = train_labels.astype('float32')\n",
    "y_test = test_labels.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "25000/25000 [==============================] - 2s 74us/step - loss: 0.4626 - binary_accuracy: 0.8240\n",
      "Epoch 2/5\n",
      "25000/25000 [==============================] - 2s 63us/step - loss: 0.2689 - binary_accuracy: 0.9090\n",
      "Epoch 3/5\n",
      "25000/25000 [==============================] - 2s 63us/step - loss: 0.2063 - binary_accuracy: 0.9278\n",
      "Epoch 4/5\n",
      "25000/25000 [==============================] - 2s 64us/step - loss: 0.1723 - binary_accuracy: 0.9394\n",
      "Epoch 5/5\n",
      "25000/25000 [==============================] - 2s 64us/step - loss: 0.1492 - binary_accuracy: 0.9486\n",
      "fit>  {'loss': [0.46256480371475217, 0.2688534903907776, 0.20628301260948181, 0.17230818962574004, 0.14920373081207275], 'binary_accuracy': [0.8240000002861023, 0.9090400002288819, 0.9278400001716613, 0.9393599998283386, 0.9485600004577637]}\n",
      "25000/25000 [==============================] - 2s 63us/step\n",
      "evaluate>  [0.30629473545074465, 0.881]\n"
     ]
    }
   ],
   "source": [
    "# 模型没有从测试集中拆分验证集\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=0.001),\n",
    "              loss=losses.binary_crossentropy,\n",
    "              metrics=[metrics.binary_accuracy])\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=5, batch_size=512)\n",
    "print('fit> ', history.history)\n",
    "\n",
    "eval_result = model.evaluate(x_test, y_test)\n",
    "print('evaluate> ', eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "15000/15000 [==============================] - 2s 112us/step - loss: 0.5114 - acc: 0.7782 - val_loss: 0.4208 - val_acc: 0.8365\n",
      "Epoch 2/5\n",
      "15000/15000 [==============================] - 1s 91us/step - loss: 0.3068 - acc: 0.9019 - val_loss: 0.3058 - val_acc: 0.8911\n",
      "Epoch 3/5\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.2209 - acc: 0.9310 - val_loss: 0.3313 - val_acc: 0.8648\n",
      "Epoch 4/5\n",
      "15000/15000 [==============================] - 2s 112us/step - loss: 0.1730 - acc: 0.9457 - val_loss: 0.2773 - val_acc: 0.8882\n",
      "Epoch 5/5\n",
      "15000/15000 [==============================] - 2s 114us/step - loss: 0.1430 - acc: 0.9557 - val_loss: 0.3002 - val_acc: 0.8821\n",
      "fit>  {'val_loss': [0.420804176568985, 0.3057797256946564, 0.3313155623912811, 0.2773297059059143, 0.3002026237487793], 'val_acc': [0.836499999332428, 0.8911000007629395, 0.8648000001907349, 0.8882000002861022, 0.8821000005722046], 'loss': [0.5114460351785024, 0.30675576764742535, 0.22086736146608987, 0.17301243742307026, 0.1429766508658727], 'acc': [0.7782000001271566, 0.901933333269755, 0.9309999998410543, 0.9457333330472311, 0.9557333335558573]}\n",
      "25000/25000 [==============================] - 2s 62us/step\n",
      "evaluate>  [0.31774706316947937, 0.8716]\n"
     ]
    }
   ],
   "source": [
    "# 模型加入验证集\n",
    "VALIDATION_SET_NUM = 10000\n",
    "x_val = x_train[:VALIDATION_SET_NUM]\n",
    "y_val = y_train[:VALIDATION_SET_NUM]\n",
    "x_train_ = x_train[VALIDATION_SET_NUM:]\n",
    "y_train_ = y_train[VALIDATION_SET_NUM:]\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train_, y_train_, \n",
    "                    epochs=5, batch_size=512,\n",
    "                    validation_data=(x_val, y_val))\n",
    "print('fit> ', history.history)\n",
    "\n",
    "eval_result = model.evaluate(x_test, y_test)\n",
    "print('evaluate> ', eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "15000/15000 [==============================] - 2s 133us/step - loss: 0.5026 - acc: 0.7796 - val_loss: 0.3574 - val_acc: 0.8748\n",
      "Epoch 2/5\n",
      "15000/15000 [==============================] - 2s 105us/step - loss: 0.2751 - acc: 0.9102 - val_loss: 0.3411 - val_acc: 0.8597\n",
      "Epoch 3/5\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 0.2031 - acc: 0.9294 - val_loss: 0.3176 - val_acc: 0.8704\n",
      "Epoch 4/5\n",
      "15000/15000 [==============================] - 1s 95us/step - loss: 0.1539 - acc: 0.9477 - val_loss: 0.2997 - val_acc: 0.8809\n",
      "Epoch 5/5\n",
      "15000/15000 [==============================] - 1s 95us/step - loss: 0.1265 - acc: 0.9578 - val_loss: 0.3395 - val_acc: 0.8700\n",
      "25000/25000 [==============================] - 2s 72us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3759273798465729, 0.85772]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 层改为32个神经网络单元\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(32, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x_train_, y_train_, epochs=5, batch_size=512, validation_data=(x_val, y_val))\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "15000/15000 [==============================] - 2s 112us/step - loss: 0.4958 - acc: 0.7962 - val_loss: 0.3884 - val_acc: 0.8671\n",
      "Epoch 2/5\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 0.3172 - acc: 0.9031 - val_loss: 0.3233 - val_acc: 0.8814\n",
      "Epoch 3/5\n",
      "15000/15000 [==============================] - 1s 97us/step - loss: 0.2459 - acc: 0.9234 - val_loss: 0.2973 - val_acc: 0.8845\n",
      "Epoch 4/5\n",
      "15000/15000 [==============================] - 1s 91us/step - loss: 0.2028 - acc: 0.9388 - val_loss: 0.2766 - val_acc: 0.8902\n",
      "Epoch 5/5\n",
      "15000/15000 [==============================] - 2s 102us/step - loss: 0.1722 - acc: 0.9470 - val_loss: 0.2752 - val_acc: 0.8886\n",
      "25000/25000 [==============================] - 1s 58us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2917386550998688, 0.88328]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 改为一层\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x_train_, y_train_, epochs=5, batch_size=512, validation_data=(x_val, y_val))\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "15000/15000 [==============================] - 2s 122us/step - loss: 0.5083 - acc: 0.7772 - val_loss: 0.3760 - val_acc: 0.8570\n",
      "Epoch 2/5\n",
      "15000/15000 [==============================] - 1s 97us/step - loss: 0.2811 - acc: 0.9041 - val_loss: 0.3082 - val_acc: 0.8765\n",
      "Epoch 3/5\n",
      "15000/15000 [==============================] - 1s 93us/step - loss: 0.2027 - acc: 0.9297 - val_loss: 0.2844 - val_acc: 0.8842\n",
      "Epoch 4/5\n",
      "15000/15000 [==============================] - 1s 91us/step - loss: 0.1522 - acc: 0.9482 - val_loss: 0.3363 - val_acc: 0.8706\n",
      "Epoch 5/5\n",
      "15000/15000 [==============================] - 2s 103us/step - loss: 0.1221 - acc: 0.9609 - val_loss: 0.3096 - val_acc: 0.8815\n",
      "25000/25000 [==============================] - 2s 65us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.34428353609085083, 0.86976]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 改为三层\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x_train_, y_train_, epochs=5, batch_size=512, validation_data=(x_val, y_val))\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "15000/15000 [==============================] - 2s 117us/step - loss: 0.1726 - acc: 0.7817 - val_loss: 0.1183 - val_acc: 0.8747\n",
      "Epoch 2/5\n",
      "15000/15000 [==============================] - 1s 91us/step - loss: 0.0911 - acc: 0.9065 - val_loss: 0.0931 - val_acc: 0.8892\n",
      "Epoch 3/5\n",
      "15000/15000 [==============================] - 2s 114us/step - loss: 0.0657 - acc: 0.9296 - val_loss: 0.0896 - val_acc: 0.8824\n",
      "Epoch 4/5\n",
      "15000/15000 [==============================] - 1s 94us/step - loss: 0.0512 - acc: 0.9457 - val_loss: 0.0885 - val_acc: 0.8801\n",
      "Epoch 5/5\n",
      "15000/15000 [==============================] - 1s 93us/step - loss: 0.0408 - acc: 0.9577 - val_loss: 0.0875 - val_acc: 0.8792\n",
      "25000/25000 [==============================] - 1s 56us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.09327613470554352, 0.87304]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 损失函数改为mse\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop', loss='mse', metrics=['accuracy'])\n",
    "model.fit(x_train_, y_train_, epochs=5, batch_size=512, validation_data=(x_val, y_val))\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "15000/15000 [==============================] - 2s 126us/step - loss: 0.4727 - acc: 0.8059 - val_loss: 0.3529 - val_acc: 0.8750\n",
      "Epoch 2/5\n",
      "15000/15000 [==============================] - 1s 96us/step - loss: 0.2758 - acc: 0.9079 - val_loss: 0.2862 - val_acc: 0.8869\n",
      "Epoch 3/5\n",
      "15000/15000 [==============================] - 1s 93us/step - loss: 0.1943 - acc: 0.9353 - val_loss: 0.2790 - val_acc: 0.8847\n",
      "Epoch 4/5\n",
      "15000/15000 [==============================] - 1s 92us/step - loss: 0.1479 - acc: 0.9533 - val_loss: 0.2876 - val_acc: 0.8857\n",
      "Epoch 5/5\n",
      "15000/15000 [==============================] - 2s 104us/step - loss: 0.1159 - acc: 0.9617 - val_loss: 0.3127 - val_acc: 0.8787\n",
      "25000/25000 [==============================] - 1s 59us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.34445818514347076, 0.86972]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 激活函数改为tanh\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='tanh', input_shape=(10000,)))\n",
    "model.add(layers.Dense(16, activation='tanh'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x_train_, y_train_, epochs=5, batch_size=512, validation_data=(x_val, y_val))\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "15000/15000 [==============================] - 2s 108us/step - loss: 0.6228 - acc: 0.6798 - val_loss: 0.5839 - val_acc: 0.7445\n",
      "Epoch 2/5\n",
      "15000/15000 [==============================] - 1s 77us/step - loss: 0.5458 - acc: 0.7813 - val_loss: 0.5451 - val_acc: 0.7799\n",
      "Epoch 3/5\n",
      "15000/15000 [==============================] - 1s 77us/step - loss: 0.5053 - acc: 0.8277 - val_loss: 0.5260 - val_acc: 0.7669\n",
      "Epoch 4/5\n",
      "15000/15000 [==============================] - 1s 79us/step - loss: 0.4759 - acc: 0.8547 - val_loss: 0.5003 - val_acc: 0.8408\n",
      "Epoch 5/5\n",
      "15000/15000 [==============================] - 1s 78us/step - loss: 0.4525 - acc: 0.8794 - val_loss: 0.4888 - val_acc: 0.8269\n",
      "25000/25000 [==============================] - 1s 47us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4939744903182983, 0.80756]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 改为1层1个神经网络单元\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(1, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x_train_, y_train_, epochs=5, batch_size=512, validation_data=(x_val, y_val))\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 尝试了这么多模型的结构，怎么都差不多？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 参考资料\n",
    "* [Getting started with the Keras Sequential model](https://keras.io/getting-started/sequential-model-guide/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
